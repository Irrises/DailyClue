<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <meta name="title" content="Seek-and-Solve: Benchmarking MLLMs for Visual Clue-Driven Reasoning in Daily Scenarios">
  <meta name="description" content="We introduce DailyClue, a benchmark designed for visual clue-driven reasoning in daily scenarios, spanning four major daily domains and 16 distinct subtasks.">
  <meta name="keywords" content="DailyClue, MLLM, Visual Reasoning, Benchmark, Multimodal, ACL">
  <meta name="author" content="Anonymous Authors">
  
  <meta property="og:site_name" content="ACL 2025 Submission">
  <meta property="og:title" content="Seek-and-Solve: DailyClue Benchmark">
  <meta property="og:description" content="Benchmarking MLLMs for Visual Clue-Driven Reasoning in Daily Scenarios.">
  <meta property="og:image" content="static/images/teaser.png">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:image" content="static/images/teaser.png">

  <title>Seek-and-Solve: DailyClue Benchmark</title>
  
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <style>
    /* Âä®ÊÄÅÊ∏êÂèòÊ†áÈ¢òÂä®ÁîªÂÆö‰πâ */
    @keyframes gradient-move {
      0% { background-position: 0% 50%; }
      50% { background-position: 100% 50%; }
      100% { background-position: 0% 50%; }
    }

    /* LongVT È£éÊ†ºÁöÑ Cyber Ê†áÈ¢òÊ†∑Âºè */
    .cyber-title {
      background-image: linear-gradient(90deg, #ff00cc 0%, #3333ff 50%, #00ccff 100%);
      background-size: 400% auto;
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
      background-clip: text;
      color: transparent;
      animation: gradient-move 5s ease infinite;
      font-weight: 800;
      filter: drop-shadow(0px 2px 4px rgba(0,0,0,0.1));
    }
    
    .table-container {
      overflow-x: auto;
    }
    
    .table.is-small th, .table.is-small td {
      padding: 0.5em 0.4em;
      font-size: 0.85rem;
    }

    .table th {
      background-color: #f5f5f5;
      color: #363636;
      vertical-align: middle;
      text-align: center;
    }

    .table td {
      text-align: center;
      vertical-align: middle;
    }

    .table td:first-child {
      text-align: left; 
      font-weight: 500;
    }
    
    .best-score {
      font-weight: bold;
      color: #d32f2f;
    }
    
    .second-best {
      text-decoration: underline;
      font-weight: bold;
      color: #000;
    }

    .section-header-row {
      background-color: #e8e8e8 !important;
      font-weight: bold;
      text-align: center;
      color: #333;
    }

    .diff-pos { color: #2e7d32; font-size: 0.9em; font-weight: bold; } 
    .diff-neg { color: #c62828; font-size: 0.9em; font-weight: bold; } 
    .caption { font-size: 0.9em; color: #666; margin-top: 5px; text-align: center;}
  </style>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title cyber-title">
            Seek-and-Solve: Benchmarking MLLMs for <br>
            Visual Clue-Driven Reasoning in Daily Scenarios
          </h1>
          
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <strong>Anonymous Authors</strong><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>ACL 2025 Submission</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org/abs/2025.XXXXX" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fas fa-file-pdf"></i></span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/YOUR_USERNAME/DailyClue" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fab fa-github"></i></span>
                  <span>Code</span>
                </a>
              </span>
              <span class="link-block">
                <a href="#" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="far fa-images"></i></span>
                  <span>Data</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/teaser.png" alt="DailyClue Overview" style="width: 100%; border-radius: 10px; box-shadow: 0 4px 8px 0 rgba(0,0,0,0.2);">
      <h2 class="subtitle has-text-centered" style="margin-top: 15px;">
        <span class="dnerf">DailyClue</span> is a benchmark designed for visual clue-driven reasoning in daily scenarios, covering four major domains: Location, Spatial, Daily Commonsense, and Scientific Commonsense.
      </h2>
    </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Daily scenarios are characterized by visual richness, requiring Multimodal Large Language Models (MLLMs) to filter noise and identify decisive visual clues for accurate reasoning. Yet, current benchmarks predominantly aim at evaluating MLLMs' pre-existing knowledge or perceptual understanding, often neglecting the critical capability of reasoning.
          </p>
          <p>
            To bridge this gap, we introduce <strong>DailyClue</strong>, a benchmark designed for visual clue-driven reasoning in daily scenarios. Our construction is guided by two core principles: (1) strict grounding in authentic daily activities, and (2) challenging query design that necessitates more than surface-level perception. Instead of simple recognition, our questions compel MLLMs to actively explore suitable visual clues and leverage them for subsequent reasoning. To this end, we curate a comprehensive dataset spanning four major daily domains and 16 distinct subtasks.
          </p>
          <p>
            Comprehensive evaluation across MLLMs and agentic models underscores the formidable challenge posed by our benchmark. Our analysis reveals several critical insights, emphasizing that the accurate identification of visual clues is essential for robust reasoning.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Data Construction Pipeline</h2>
        <div class="content has-text-justified">
          <p>
            We employ a carefully controlled generation and filtering pipeline to ensure high-quality, reasoning-intensive questions. The process involves candidate triplet generation by top-tier MLLMs, followed by multi-model verification and rigorous human cross-checks.
          </p>
          <img src="static/images/pipeline.png" alt="Construction Pipeline" style="width: 100%; margin-top: 20px; border: 1px solid #e1e1e1; border-radius: 8px;">
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Reasoning Examples</h2>
        <p class="subtitle is-6">
            DailyClue features four daily life scenarios across 16 reasoning subtasks.
        </p>
        <img src="static/images/examples.png" alt="DailyClue Examples" style="width: 100%; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1);">
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Performance Comparison</h2>
        <div class="content has-text-justified">
          <p>
            Performance comparison on the DailyClue benchmark. Metrics denote accuracy (%). The best result is highlighted in <span class="best-score">bold red</span>, and the second best is <span class="second-best">underlined</span>.
          </p>
        </div>
        
        <div class="table-container">
          <table class="table is-bordered is-striped is-hoverable is-fullwidth is-small">
            <thead>
              <tr>
                <th>Model</th>
                <th>Overall</th>
                <th>Location<br>Identification</th>
                <th>Spatial<br>Relationship</th>
                <th>Daily<br>Commonsense</th>
                <th>Scientific<br>Commonsense</th>
              </tr>
            </thead>
            <tbody>
              <tr class="section-header-row"><td colspan="6">Open-source MLLMs</td></tr>
              <tr><td>LLaVA-OneVision-7B</td><td>24.47</td><td>10.50</td><td>34.97</td><td>25.56</td><td>31.71</td></tr>
              <tr><td>LLaVA-OneVision-72B</td><td>33.18</td><td>15.50</td><td>47.85</td><td>33.33</td><td>42.28</td></tr>
              <tr><td>LLaVA-OneVision-1.5-8B-Instruct</td><td>29.43</td><td>10.50</td><td>47.85</td><td>27.78</td><td>38.21</td></tr>
              <tr><td>InternVL3-8B</td><td>31.08</td><td>13.50</td><td>31.67</td><td>31.67</td><td>41.46</td></tr>
              <tr><td>InternVL3-38B</td><td>36.94</td><td>17.00</td><td>47.85</td><td>47.22</td><td>39.84</td></tr>
              <tr><td>InternVL3-78B</td><td>40.84</td><td>18.00</td><td class="best-score">54.60</td><td class="second-best">52.78</td><td>42.28</td></tr>
              <tr><td>InternVL-3.5-38B</td><td>36.91</td><td>14.00</td><td class="second-best">49.69</td><td>43.33</td><td>43.90</td></tr>
              <tr><td>Qwen2.5-VL-7B</td><td>30.63</td><td>15.00</td><td>39.88</td><td>37.22</td><td>34.15</td></tr>
              <tr><td>Qwen2.5-VL-32B</td><td>35.59</td><td>21.50</td><td>42.94</td><td>42.78</td><td>38.21</td></tr>
              <tr><td>Qwen2.5-VL-72B</td><td class="second-best">40.84</td><td class="best-score">24.50</td><td>47.85</td><td>48.33</td><td>47.15</td></tr>
              <tr><td>Qwen3-VL-235B-A22B-Thinking</td><td class="best-score">44.59</td><td class="second-best">23.00</td><td>49.08</td><td class="best-score">56.67</td><td class="best-score">56.10</td></tr>
              <tr><td>Qwen3-VL-235B-A22B-Instruct</td><td>40.69</td><td>22.50</td><td>46.63</td><td>50.00</td><td class="second-best">48.78</td></tr>

              <tr class="section-header-row"><td colspan="6">Close-source MLLMs</td></tr>
              <tr><td>ü•â Gemini-2.5-Flash</td><td>50.00</td><td>32.50</td><td>55.83</td><td class="second-best">59.44</td><td>56.91</td></tr>
              <tr><td>ü•á Gemini-2.5-Pro</td><td class="best-score">56.90</td><td class="best-score">41.50</td><td class="best-score">61.35</td><td class="best-score">62.77</td><td class="best-score">67.48</td></tr>
              <tr><td>Claude-3.7-Sonnet</td><td>41.14</td><td>18.50</td><td>57.06</td><td>47.22</td><td>47.97</td></tr>
              <tr><td>Claude-sonnet-4</td><td>41.74</td><td>22.00</td><td>52.15</td><td>48.89</td><td>49.59</td></tr>
              <tr><td>Claude-sonnet-4.5</td><td>41.74</td><td>21.00</td><td>53.99</td><td>49.44</td><td>47.97</td></tr>
              <tr><td>o4-mini</td><td>47.00</td><td>25.50</td><td class="second-best">58.28</td><td>58.33</td><td>50.41</td></tr>
              <tr><td>ü•à GPT-5</td><td class="second-best">50.90</td><td class="second-best">38.00</td><td>57.67</td><td>51.67</td><td class="second-best">61.79</td></tr>

              <tr class="section-header-row"><td colspan="6">Agentic Models</td></tr>
              <tr><td>DeepEyes-7B</td><td>30.93</td><td>18.50</td><td class="second-best">44.17</td><td>30.00</td><td>34.96</td></tr>
              <tr><td>VLM-R3</td><td>33.18</td><td class="second-best">19.00</td><td>42.33</td><td class="second-best">36.11</td><td class="second-best">39.84</td></tr>
              <tr><td>TreeVGR-7B</td><td>27.78</td><td>14.00</td><td>40.49</td><td>27.18</td><td>33.33</td></tr>
              <tr><td>REVPT</td><td>25.83</td><td>6.50</td><td>38.04</td><td>32.22</td><td>31.71</td></tr>
              <tr><td>Thyme</td><td class="best-score">46.25</td><td class="best-score">69.00</td><td>42.33</td><td>29.44</td><td>39.02</td></tr>
              <tr><td>PyVision</td><td class="second-best">39.48</td><td>18.50</td><td class="best-score">47.23</td><td class="best-score">48.33</td><td class="best-score">50.40</td></tr>

              <tr class="section-header-row"><td colspan="6">Human Baseline</td></tr>
              <tr><td>Human Baseline</td><td>45.50</td><td>19.33</td><td>70.67</td><td>40.00</td><td>52.00</td></tr>
            </tbody>
          </table>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Further Findings</h2>
        <div class="content has-text-justified">
          <p>We conducted extensive analysis to understand the role of visual clues in reasoning. Our findings highlight the critical importance of accurate visual clue identification.</p>
        </div>
      </div>
    </div>

    <div class="columns is-centered">
      <div class="column is-full-width">
        <div class="box">
          <h4 class="title is-4">1. Probing MLLMs with Explicit Clues</h4>
          <div class="content has-text-justified">
            <p>
              We investigated how performance changes when models are conditioned on visual clues from different sources. 
              <strong>Table 3</strong> shows that performance strictly follows clue quality (Qwen < Claude < Gemini < GT).
              Notably, injecting <strong>Ground Truth (GT) clues</strong> yields substantial gains across all models (e.g., Claude +14.86%), indicating that performance is heavily bottlenecked by inaccurate clue extraction.
            </p>
          </div>
          <div class="table-container">
            <table class="table is-bordered is-hoverable is-fullwidth">
              <thead>
                <tr>
                  <th>Target Model</th>
                  <th>Qwen Clue</th>
                  <th>Claude Clue</th>
                  <th>Gemini Clue</th>
                  <th>GT Clue</th>
                  <th>No Clue (Baseline)</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td><strong>Qwen2.5-VL-72B</strong></td>
                  <td>40.09 <span class="diff-neg">(-0.75)</span></td>
                  <td>41.29 <span class="diff-pos">(+0.45)</span></td>
                  <td>48.80 <span class="diff-pos">(+7.96)</span></td>
                  <td>51.50 <span class="diff-pos">(+10.66)</span></td>
                  <td>40.84</td>
                </tr>
                <tr>
                  <td><strong>Claude-3.7</strong></td>
                  <td>42.49 <span class="diff-pos">(+1.35)</span></td>
                  <td>43.39 <span class="diff-pos">(+2.25)</span></td>
                  <td>51.95 <span class="diff-pos">(+10.81)</span></td>
                  <td>56.00 <span class="diff-pos">(+14.86)</span></td>
                  <td>41.14</td>
                </tr>
                <tr>
                  <td><strong>Gemini-2.5-Pro</strong></td>
                  <td>52.85 <span class="diff-neg">(-4.05)</span></td>
                  <td>53.15 <span class="diff-neg">(-3.75)</span></td>
                  <td>55.26 <span class="diff-neg">(-1.64)</span></td>
                  <td>58.55 <span class="diff-pos">(+1.65)</span></td>
                  <td>56.90</td>
                </tr>
              </tbody>
            </table>
            <p class="caption">Table 3: Effect of clue sources on MLLM reasoning. <span class="diff-pos">Green</span> indicates improvement, <span class="diff-neg">Red</span> indicates performance drop.</p>
          </div>
        </div>
      </div>
    </div>

    <div class="columns is-centered">
      <div class="column is-full-width">
        <div class="box">
          <h4 class="title is-4">2. Efficacy of Active Clue Seeking</h4>
          <div class="columns is-vcentered">
            <div class="column is-6">
              <div class="content has-text-justified">
                <p>
                  Does explicitly asking the model to "look for clues" help? 
                  As shown in <strong>Figure 6</strong>, mandating active visual clues within the Chain-of-Thought (CoT) acts as a critical anchor.
                  Our proposed method <strong>(Ours)</strong> consistently outperforms direct answering (No CoT) and standard reasoning (Vanilla CoT) across all models.
                </p>
              </div>
            </div>
            <div class="column is-6 has-text-centered">
              <img src="static/images/figure6.png" alt="Impact of Visual Clue Reasoning" style="width: 100%; max-width: 450px; border-radius: 5px;">
              <p class="caption">Figure 6: Impact of visual-clue-reasoning on accuracy.</p>
            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="columns is-centered">
      <div class="column is-full-width">
        <div class="box">
          <h4 class="title is-4">3. Rigorous Evaluation: "Right Answer, Wrong Reason"</h4>
          <div class="columns is-vcentered">
            <div class="column is-6 has-text-centered">
              <img src="static/images/figure7.png" alt="Rigorous Evaluation Protocol" style="width: 100%; max-width: 450px; border-radius: 5px;">
              <p class="caption">Figure 7: Accuracy comparison between General and Rigorous Evaluation Protocols.</p>
            </div>
            <div class="column is-6">
              <div class="content has-text-justified">
                <p>
                  Superficial accuracy may belie a critical disconnect between reasoning and prediction.
                  We introduced a <strong>Rigorous Evaluation Protocol</strong> to check if the model's visual clues actually match the Ground Truth.
                  As seen in <strong>Figure 7</strong>, while Qwen and Claude show noticeable drops (indicating "lucky guesses" based on illusionary clues), <strong>Gemini-2.5-Pro</strong> exhibits exceptional stability (-0.44%), demonstrating superior reasoning fidelity.
                </p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{dailyclue2025,
  title={Seek-and-Solve: Benchmarking MLLMs for Visual Clue-Driven Reasoning in Daily Scenarios},
  author={Anonymous Authors},
  journal={ACL Submission},
  year={2025}
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <p>
        This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
      </p>
    </div>
  </div>
</footer>

</body>
</html>
