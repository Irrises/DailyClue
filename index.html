<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <meta name="title" content="Seek-and-Solve: Benchmarking MLLMs for Visual Clue-Driven Reasoning in Daily Scenarios">
  <meta name="description" content="We introduce DailyClue, a benchmark designed for visual clue-driven reasoning in daily scenarios, spanning four major daily domains and 16 distinct subtasks.">
  <meta name="keywords" content="DailyClue, MLLM, Visual Reasoning, Benchmark, Multimodal, ACL">
  <meta name="author" content="Anonymous Authors">
  
  <meta property="og:site_name" content="ACL 2025 Submission">
  <meta property="og:title" content="Seek-and-Solve: DailyClue Benchmark">
  <meta property="og:description" content="Benchmarking MLLMs for Visual Clue-Driven Reasoning in Daily Scenarios.">
  <meta property="og:image" content="static/images/teaser.jpg">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:image" content="static/images/teaser.jpg">

  <title>Seek-and-Solve: DailyClue Benchmark</title>
  
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <style>
    .title-gradient {
      background: linear-gradient(120deg, #bd34fe 30%, #41d1ff 90%);
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
      font-weight: 800;
      filter: drop-shadow(0px 2px 4px rgba(0,0,0,0.1));
    }
    
    .table-container {
      overflow-x: auto;
    }
    
    .table th {
      background-color: #f5f5f5;
      color: #363636;
      vertical-align: middle;
      text-align: center;
    }

    .table td {
      text-align: center;
      vertical-align: middle;
    }

    .table td:first-child {
      text-align: left; /* Model names aligned left */
    }

    .best-score {
      font-weight: bold;
      color: #d32f2f; /* Red for best */
    }

    .second-best {
      text-decoration: underline;
      font-weight: bold;
    }

    .section-header-row {
      background-color: #e8e8e8 !important;
      font-weight: bold;
      text-align: center;
    }
  </style>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title title-gradient">
            Seek-and-Solve: Benchmarking MLLMs for <br>
            Visual Clue-Driven Reasoning in Daily Scenarios
          </h1>

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <strong>Anonymous Authors</strong><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>ACL 2025 Submission</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org/abs/2025.XXXXX" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fas fa-file-pdf"></i></span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/YOUR_USERNAME/DailyClue" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fab fa-github"></i></span>
                  <span>Code</span>
                </a>
              </span>
              <span class="link-block">
                <a href="#" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="far fa-images"></i></span>
                  <span>Data</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/teaser.jpg" alt="DailyClue Overview" style="width: 100%; border-radius: 10px; box-shadow: 0 4px 8px 0 rgba(0,0,0,0.2);">
      <h2 class="subtitle has-text-centered" style="margin-top: 15px;">
        <span class="dnerf">DailyClue</span> is a benchmark designed for visual clue-driven reasoning in daily scenarios, covering four major domains: Location, Spatial, Daily Commonsense, and Scientific Commonsense.
      </h2>
    </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
          <p>
            Daily scenarios are characterized by visual richness, requiring Multimodal Large Language Models (MLLMs) to filter noise and identify decisive visual clues for accurate reasoning. Yet, current benchmarks predominantly aim at evaluating MLLMs' pre-existing knowledge or perceptual understanding, often neglecting the critical capability of reasoning.
          </p>
          <p>
            To bridge this gap, we introduce <strong>DailyClue</strong>, a benchmark designed for visual clue-driven reasoning in daily scenarios. Our construction is guided by two core principles: (1) strict grounding in authentic daily activities, and (2) challenging query design that necessitates more than surface-level perception.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Data Construction Pipeline</h2>
        <div class="content has-text-justified">
          <p>
            We employ a carefully controlled generation and filtering pipeline to ensure high-quality, reasoning-intensive questions. The process involves candidate triplet generation by top-tier MLLMs, followed by multi-model verification and rigorous human cross-checks.
          </p>
          <img src="static/images/pipeline.jpg" alt="Construction Pipeline" style="width: 100%; margin-top: 20px; border: 1px solid #e1e1e1; border-radius: 8px;">
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Reasoning Examples</h2>
        <p class="subtitle is-6">
            DailyClue features four daily life scenarios across 16 reasoning subtasks.
        </p>
        <img src="static/images/examples.jpg" alt="DailyClue Examples" style="width: 100%; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1);">
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Performance Comparison</h2>
        <div class="content has-text-justified">
          <p>
            Performance comparison on the DailyClue benchmark. Metrics denote accuracy (%). The best result is highlighted in <span class="best-score">bold red</span>, and the second best is <span class="second-best">underlined</span>.
          </p>
        </div>

        <div class="table-container">
          <table class="table is-bordered is-striped is-hoverable is-fullwidth is-small">
            <thead>
              <tr>
                <th>Model</th>
                <th>Overall</th>
                <th>Location Identification</th>
                <th>Spatial Relationship</th>
                <th>Daily Commonsense</th>
                <th>Scientific Commonsense</th>
              </tr>
            </thead>
            <tbody>
              <tr class="section-header-row">
                <td colspan="6">Open-source MLLMs</td>
              </tr>
              <tr><td>LLaVA-OneVision-7B</td><td>24.47</td><td>10.50</td><td>34.97</td><td>25.56</td><td>31.71</td></tr>
              <tr><td>LLaVA-OneVision-72B</td><td>33.18</td><td>15.50</td><td>47.85</td><td>33.33</td><td>42.28</td></tr>
              <tr><td>LLaVA-OneVision-1.5-8B-Instruct</td><td>29.43</td><td>10.50</td><td>47.85</td><td>27.78</td><td>38.21</td></tr>
              <tr><td>InternVL3-8B</td><td>31.08</td><td>13.50</td><td>31.67</td><td>31.67</td><td>41.46</td></tr>
              <tr><td>InternVL3-38B</td><td>36.94</td><td>17.00</td><td>47.85</td><td>47.22</td><td>39.84</td></tr>
              <tr><td>InternVL3-78B</td><td>40.84</td><td>18.00</td><td class="best-score">54.60</td><td class="second-best">52.78</td><td>42.28</td></tr>
              <tr><td>InternVL-3.5-38B</td><td>36.91</td><td>14.00</td><td class="second-best">49.69</td><td>43.33</td><td>43.90</td></tr>
              <tr><td>Qwen2.5-VL-7B</td><td>30.63</td><td>15.00</td><td>39.88</td><td>37.22</td><td>34.15</td></tr>
              <tr><td>Qwen2.5-VL-32B</td><td>35.59</td><td>21.50</td><td>42.94</td><td>42.78</td><td>38.21</td></tr>
              <tr><td>Qwen2.5-VL-72B</td><td class="second-best">40.84</td><td class="best-score">24.50</td><td>47.85</td><td>48.33</td><td>47.15</td></tr>
              <tr><td>Qwen3-VL-235B-A22B-Thinking</td><td class="best-score">44.59</td><td class="second-best">23.00</td><td>49.08</td><td class="best-score">56.67</td><td class="best-score">56.10</td></tr>
              <tr><td>Qwen3-VL-235B-A22B-Instruct</td><td>40.69</td><td>22.50</td><td>46.63</td><td>50.00</td><td class="second-best">48.78</td></tr>

              <tr class="section-header-row">
                <td colspan="6">Close-source MLLMs</td>
              </tr>
              <tr><td>Gemini-2.5-Flash ðŸ¥‰</td><td>50.00</td><td>32.50</td><td>55.83</td><td class="second-best">59.44</td><td>56.91</td></tr>
              <tr><td>Gemini-2.5-Pro ðŸ¥‡</td><td class="best-score">56.90</td><td class="best-score">41.50</td><td class="best-score">61.35</td><td class="best-score">62.77</td><td class="best-score">67.48</td></tr>
              <tr><td>Claude-3.7-Sonnet</td><td>41.14</td><td>18.50</td><td>57.06</td><td>47.22</td><td>47.97</td></tr>
              <tr><td>Claude-sonnet-4</td><td>41.74</td><td>22.00</td><td>52.15</td><td>48.89</td><td>49.59</td></tr>
              <tr><td>Claude-sonnet-4.5</td><td>41.74</td><td>21.00</td><td>53.99</td><td>49.44</td><td>47.97</td></tr>
              <tr><td>o4-mini</td><td>47.00</td><td>25.50</td><td class="second-best">58.28</td><td>58.33</td><td>50.41</td></tr>
              <tr><td>GPT-5 ðŸ¥ˆ</td><td class="second-best">50.90</td><td class="second-best">38.00</td><td>57.67</td><td>51.67</td><td class="second-best">61.79</td></tr>

              <tr class="section-header-row">
                <td colspan="6">Agentic Models</td>
              </tr>
              <tr><td>DeepEyes-7B</td><td>30.93</td><td>18.50</td><td class="second-best">44.17</td><td>30.00</td><td>34.96</td></tr>
              <tr><td>VLM-R3</td><td>33.18</td><td class="second-best">19.00</td><td>42.33</td><td class="second-best">36.11</td><td class="second-best">39.84</td></tr>
              <tr><td>TreeVGR-7B</td><td>27.78</td><td>14.00</td><td>40.49</td><td>27.18</td><td>33.33</td></tr>
              <tr><td>REVPT</td><td>25.83</td><td>6.50</td><td>38.04</td><td>32.22</td><td>31.71</td></tr>
              <tr><td>Thyme</td><td class="best-score">46.25</td><td class="best-score">69.00</td><td>42.33</td><td>29.44</td><td>39.02</td></tr>
              <tr><td>PyVision</td><td class="second-best">39.48</td><td>18.50</td><td class="best-score">47.23</td><td class="best-score">48.33</td><td class="best-score">50.40</td></tr>

              <tr class="section-header-row">
                <td colspan="6">Human Baseline</td>
              </tr>
              <tr><td>Human Baseline</td><td>45.50</td><td>19.33</td><td>70.67</td><td>40.00</td><td>52.00</td></tr>
            </tbody>
          </table>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 has-text-centered">Further Findings</h2>
        <div class="content">
          <ul>
            <li>
              <strong>Accurate Visual Clues are Critical:</strong> Our analysis reveals that model performance is heavily bottlenecked by the failure to accurately capture critical visual semantics. Injecting Ground Truth (GT) clues yields substantial gains across all models.
            </li>
            <li>
              <strong>Active Clue Seeking Improves Reasoning:</strong> Explicitly prompting models to actively seek visual clues within their Chain-of-Thought (CoT) acts as a critical anchor, consistently improving accuracy.
            </li>
            <li>
              <strong>"Right Answer, Wrong Reason":</strong> Models sometimes arrive at correct answers through illusionary or irrelevant clues, though top-tier models like Gemini-2.5-Pro show exceptional stability.
            </li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{dailyclue2025,
  title={Seek-and-Solve: Benchmarking MLLMs for Visual Clue-Driven Reasoning in Daily Scenarios},
  author={Anonymous Authors},
  journal={ACL Submission},
  year={2025}
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="https://arxiv.org/abs/2025.XXXXX" class="external-link" disabled>
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/YOUR_USERNAME/DailyClue" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
